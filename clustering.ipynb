{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T0GI4CAwb0HR",
        "outputId": "3dcd098e-b399-42d3-89b1-2ab60c8b07fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Clustering analysis completed! All results saved in 'clu_outputs' folder.\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from sklearn.cluster import KMeans, MeanShift, AgglomerativeClustering\n",
        "from sklearn.metrics import silhouette_score, calinski_harabasz_score, davies_bouldin_score\n",
        "import os\n",
        "\n",
        "# Create output directory\n",
        "output_dir = \"clustering_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# Load dataset from UCI (Iris dataset)\n",
        "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
        "columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'species']\n",
        "df = pd.read_csv(url, names=columns)\n",
        "df.drop(columns=['species'], inplace=True)  # Remove labels\n",
        "\n",
        "# Preprocessing Techniques\n",
        "scaler_standard = StandardScaler()\n",
        "scaler_minmax = MinMaxScaler()\n",
        "pca = PCA(n_components=2)\n",
        "\n",
        "df_standard = pd.DataFrame(scaler_standard.fit_transform(df), columns=df.columns)\n",
        "df_minmax = pd.DataFrame(scaler_minmax.fit_transform(df), columns=df.columns)\n",
        "df_pca = pd.DataFrame(pca.fit_transform(df), columns=['PC1', 'PC2'])\n",
        "df_tn = pd.DataFrame(scaler_standard.fit_transform(df_minmax), columns=df.columns)  # Transform + Normalize\n",
        "df_tn_pca = pd.DataFrame(pca.fit_transform(df_tn), columns=['PC1', 'PC2'])  # Transform + Normalize + PCA\n",
        "\n",
        "# Define different preprocessing techniques\n",
        "preprocessing_methods = {\n",
        "    \"No Data Processing\": df,\n",
        "    \"Using Normalization\": df_minmax,\n",
        "    \"Using Transform\": df_standard,\n",
        "    \"Using PCA\": df_pca,\n",
        "    \"Using T+N\": df_tn,\n",
        "    \"T+N+PCA\": df_tn_pca\n",
        "}\n",
        "\n",
        "# Function to apply clustering and compute metrics\n",
        "def apply_clustering(data, n_clusters):\n",
        "    results = []\n",
        "    algorithms = {\n",
        "        \"K-Means\": KMeans(n_clusters=n_clusters, random_state=42),\n",
        "        \"Hierarchical\": AgglomerativeClustering(n_clusters=n_clusters),\n",
        "        \"Mean-Shift\": MeanShift()\n",
        "    }\n",
        "\n",
        "    for algo_name, algorithm in algorithms.items():\n",
        "        labels = algorithm.fit_predict(data)\n",
        "\n",
        "        if len(set(labels)) > 1:  # Only compute metrics if multiple clusters exist\n",
        "            silhouette = silhouette_score(data, labels)\n",
        "            calinski_harabasz = calinski_harabasz_score(data, labels)\n",
        "            davies_bouldin = davies_bouldin_score(data, labels)\n",
        "        else:\n",
        "            silhouette = calinski_harabasz = davies_bouldin = np.nan  # Not computable\n",
        "\n",
        "        results.append([algo_name, silhouette, calinski_harabasz, davies_bouldin])\n",
        "\n",
        "    return results\n",
        "\n",
        "# Store final results\n",
        "final_results = {\"K-Means\": [], \"Hierarchical\": [], \"Mean-Shift\": []}\n",
        "\n",
        "# Apply clustering to all preprocessing methods and cluster sizes\n",
        "for preprocess_name, dataset in preprocessing_methods.items():\n",
        "    for clusters in [3, 4, 5]:\n",
        "        results = apply_clustering(dataset, clusters)\n",
        "        for row in results:\n",
        "            final_results[row[0]].append([preprocess_name, clusters] + row[1:])\n",
        "\n",
        "# Convert results to DataFrame\n",
        "columns = [\"Preprocessing\", \"Clusters\", \"Silhouette Score\", \"Calinski-Harabasz\", \"Davies-Bouldin\"]\n",
        "df_kmeans = pd.DataFrame(final_results[\"K-Means\"], columns=columns)\n",
        "df_hierarchical = pd.DataFrame(final_results[\"Hierarchical\"], columns=columns)\n",
        "df_meanshift = pd.DataFrame(final_results[\"Mean-Shift\"], columns=columns)\n",
        "\n",
        "# Save tables as PNG images\n",
        "def save_table_as_image(df, title, filename):\n",
        "    fig, ax = plt.subplots(figsize=(12, 4))\n",
        "    ax.axis('tight')\n",
        "    ax.axis('off')\n",
        "    table = ax.table(cellText=df.values, colLabels=df.columns, cellLoc='center', loc='center')\n",
        "    plt.title(title)\n",
        "    plt.savefig(f\"{output_dir}/{filename}\")\n",
        "    plt.close()\n",
        "\n",
        "save_table_as_image(df_kmeans, \"Using K-Means Clustering\", \"table_kmeans.png\")\n",
        "save_table_as_image(df_hierarchical, \"Using Hierarchical Clustering\", \"table_hierarchical.png\")\n",
        "save_table_as_image(df_meanshift, \"Using Mean-Shift Clustering\", \"table_meanshift.png\")\n",
        "\n",
        "# Save results as CSV\n",
        "df_kmeans.to_csv(f\"{output_dir}/results_kmeans.csv\", index=False)\n",
        "df_hierarchical.to_csv(f\"{output_dir}/results_hierarchical.csv\", index=False)\n",
        "df_meanshift.to_csv(f\"{output_dir}/results_meanshift.csv\", index=False)\n",
        "\n",
        "# Generate Heatmap of results\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(df_kmeans.drop(columns=[\"Preprocessing\", \"Clusters\"]), annot=True, fmt=\".3f\", cmap=\"coolwarm\", ax=ax)\n",
        "plt.title(\"K-Means Performance Heatmap\")\n",
        "plt.savefig(f\"{output_dir}/heatmap_kmeans.png\")\n",
        "plt.close()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(df_hierarchical.drop(columns=[\"Preprocessing\", \"Clusters\"]), annot=True, fmt=\".3f\", cmap=\"coolwarm\", ax=ax)\n",
        "plt.title(\"Hierarchical Clustering Heatmap\")\n",
        "plt.savefig(f\"{output_dir}/heatmap_hierarchical.png\")\n",
        "plt.close()\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(8, 6))\n",
        "sns.heatmap(df_meanshift.drop(columns=[\"Preprocessing\", \"Clusters\"]), annot=True, fmt=\".3f\", cmap=\"coolwarm\", ax=ax)\n",
        "plt.title(\"Mean-Shift Clustering Heatmap\")\n",
        "plt.savefig(f\"{output_dir}/heatmap_meanshift.png\")\n",
        "plt.close()\n",
        "\n",
        "print(\" Clustering analysis completed! All results saved in 'clu_outputs' folder.\")\n"
      ]
    }
  ]
}